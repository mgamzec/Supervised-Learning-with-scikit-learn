{"cells":[{"source":"# Preprocessing and Pipelines\nImpute missing values, convert categorical data to numeric values, scale data, evaluate multiple supervised learning models simultaneously, and build pipelines to streamline your workflow","metadata":{},"cell_type":"markdown","id":"29a78fef-5115-4c8a-9abc-4878fc157327"},{"source":"## Scikit-learn requirements \n- Numeric data\n- No missing values","metadata":{},"cell_type":"markdown","id":"57f3e7c6-64bf-478f-a6d5-85fd820b9da2"},{"source":"import pandas as pd\nmusic = pd.read_csv('datasets/music_clean.csv')\nprint(music.info())","metadata":{"executionTime":82,"lastSuccessfullyExecutedCode":"import pandas as pd\nmusic = pd.read_csv('datasets/music_clean.csv')\nprint(music.info())"},"cell_type":"code","id":"88f5cf10-2ed3-4c42-acce-c57dd27cb017","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Unnamed: 0        1000 non-null   int64  \n 1   popularity        1000 non-null   float64\n 2   acousticness      1000 non-null   float64\n 3   danceability      1000 non-null   float64\n 4   duration_ms       1000 non-null   float64\n 5   energy            1000 non-null   float64\n 6   instrumentalness  1000 non-null   float64\n 7   liveness          1000 non-null   float64\n 8   loudness          1000 non-null   float64\n 9   speechiness       1000 non-null   float64\n 10  tempo             1000 non-null   float64\n 11  valence           1000 non-null   float64\n 12  genre             1000 non-null   int64  \ndtypes: float64(11), int64(2)\nmemory usage: 101.7 KB\nNone\n"}]},{"source":"## Encoding dummy variables","metadata":{},"cell_type":"markdown","id":"96f13603-d143-421c-a66a-03908a85acd5"},{"source":"import pandas as pd\nmusic_df = pd.read_csv(\"datasets/music_clean.csv\")\nmusic_dummies = pd.get_dummies(music_df[\"genre\"], drop_first=True)\nprint(music_dummies.head())","metadata":{"executionTime":91,"lastSuccessfullyExecutedCode":"import pandas as pd\nmusic_df = pd.read_csv(\"datasets/music_clean.csv\")\nmusic_dummies = pd.get_dummies(music_df[\"genre\"], drop_first=True)\nprint(music_dummies.head())"},"cell_type":"code","id":"158b2678-5462-4d62-817d-a0d95f181ac3","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"   1\n0  1\n1  1\n2  1\n3  1\n4  1\n"}]},{"source":"music_dummies = pd.concat([music_df, music_dummies], axis=1)\nmusic_dummies = music_dummies.drop(\"genre\", axis=1)","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"music_dummies = pd.concat([music_df, music_dummies], axis=1)\nmusic_dummies = music_dummies.drop(\"genre\", axis=1)"},"cell_type":"code","id":"17940e98-fa63-4c84-b6ad-de8e711ce3d7","execution_count":3,"outputs":[]},{"source":"![resim_2023-04-14_140923957](resim_2023-04-14_140923957.png)\n","metadata":{},"cell_type":"markdown","id":"cf845ef2-4748-48dc-9699-495ff5e2f737"},{"source":"## Creating dummy variables\nBeing able to include categorical features in the model building process can enhance performance as they may add information that contributes to prediction accuracy.","metadata":{},"cell_type":"markdown","id":"5e5159c7-1906-49f8-a806-22a2e5f2b80f"},{"source":"# Create music_dummies\nmusic_dummies = pd.get_dummies(music_df, drop_first=True)\n\n# Print the new DataFrame's shape\nprint(\"Shape of music_dummies: {}\".format(music_dummies.shape))","metadata":{"executionTime":36,"lastSuccessfullyExecutedCode":"# Create music_dummies\nmusic_dummies = pd.get_dummies(music_df, drop_first=True)\n\n# Print the new DataFrame's shape\nprint(\"Shape of music_dummies: {}\".format(music_dummies.shape))"},"cell_type":"code","id":"a80ac807-73a7-4f31-9637-fa2f930f4789","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Shape of music_dummies: (1000, 13)\n"}]},{"source":"As there were ten values in the \"genre\" column, nine new columns were added by a call of `pd.get_dummies()` using `drop_first=True`. After dropping the original \"`genre`\" column, there are still eight new columns in the DataFrame","metadata":{},"cell_type":"markdown","id":"e4855afe-8aea-4631-8ddd-b3ce9890a5b9"},{"source":"## Regression with categorical features\nNow we have created music_dummies, containing binary features for each song's genre, it's time to build a ridge regression model to predict song popularity.\n\nThe model will be evaluated by calculating the average RMSE, but first, we will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target valueâ€”\"popularity\".","metadata":{},"cell_type":"markdown","id":"7c5a186a-c533-4324-889a-13baa3e7b21b"},{"source":"# Import necessary modules\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score, KFold\n\n# Create X and y\nX = music_dummies.drop(\"popularity\", axis=1).values\ny = music_dummies[\"popularity\"].values\n\n# Instantiate a ridge model\nridge = Ridge(alpha=0.2)\n\n# Define k-fold cross-validation object\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Perform cross-validation\nscores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n\n# Calculate RMSE\nrmse = np.sqrt(-scores)\nprint(\"Average RMSE: {}\".format(np.mean(rmse)))\nprint(\"Standard Deviation of the target array: {}\".format(np.std(y)))","metadata":{"executionTime":32,"lastSuccessfullyExecutedCode":"# Import necessary modules\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score, KFold\n\n# Create X and y\nX = music_dummies.drop(\"popularity\", axis=1).values\ny = music_dummies[\"popularity\"].values\n\n# Instantiate a ridge model\nridge = Ridge(alpha=0.2)\n\n# Define k-fold cross-validation object\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Perform cross-validation\nscores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n\n# Calculate RMSE\nrmse = np.sqrt(-scores)\nprint(\"Average RMSE: {}\".format(np.mean(rmse)))\nprint(\"Standard Deviation of the target array: {}\".format(np.std(y)))"},"cell_type":"code","id":"7f11c311-6667-4143-a4c9-944803c1cfac","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Average RMSE: 10.033098690539362\nStandard Deviation of the target array: 14.02156909907019\n"}]},{"source":"An average RMSE of approximately 10.03 is lower than the standard deviation of the target variable (song popularity), suggesting the model is reasonably accurate.","metadata":{},"cell_type":"markdown","id":"9b0d321b-d595-49bd-af5c-28ec8bfe793b"},{"source":"## Dropping missing data\nOver the next three exercises, we are going to tidy the music_df dataset. We will create a pipeline to impute missing values and build a KNN classifier model, then use it to predict whether a song is of the \"Rock\" genre.\n\nNow, we will drop missing values accounting for less than 5% of the dataset, and convert the \"genre\" column into a binary feature.","metadata":{},"cell_type":"markdown","id":"a93e05f7-fe88-49c6-81c6-ced2b967f498"},{"source":"# Print missing values for each column\nprint(music_df.isna().sum().sort_values())\n\n# Remove values where less than 5% are missing\nmusic_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n\n# Convert genre to a binary feature\nmusic_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n\nprint(music_df.isna().sum().sort_values())\nprint(\"Shape of the `music_df`: {}\".format(music_df.shape))","metadata":{"executionTime":35,"lastSuccessfullyExecutedCode":"# Print missing values for each column\nprint(music_df.isna().sum().sort_values())\n\n# Remove values where less than 5% are missing\nmusic_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n\n# Convert genre to a binary feature\nmusic_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n\nprint(music_df.isna().sum().sort_values())\nprint(\"Shape of the `music_df`: {}\".format(music_df.shape))"},"cell_type":"code","id":"af197bf3-a5ae-4419-9d5c-8a8d3e4ee4c5","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Unnamed: 0          0\npopularity          0\nacousticness        0\ndanceability        0\nduration_ms         0\nenergy              0\ninstrumentalness    0\nliveness            0\nloudness            0\nspeechiness         0\ntempo               0\nvalence             0\ngenre               0\ndtype: int64\nUnnamed: 0          0\npopularity          0\nacousticness        0\ndanceability        0\nduration_ms         0\nenergy              0\ninstrumentalness    0\nliveness            0\nloudness            0\nspeechiness         0\ntempo               0\nvalence             0\ngenre               0\ndtype: int64\nShape of the `music_df`: (1000, 13)\n"}]},{"source":"## Pipeline for song genre prediction: I\nNow it's time to build a pipeline. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre.","metadata":{},"cell_type":"markdown","id":"0e0b6a27-571b-448e-a806-6b515f778d89"},{"source":"# Import modules\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate an imputer\nimputer = SimpleImputer()\n\n# Instantiate a knn model\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# Build steps for the pipeline\nsteps = [(\"imputer\", imputer), \n         (\"knn\", knn)]","metadata":{"executionTime":32,"lastSuccessfullyExecutedCode":"# Import modules\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate an imputer\nimputer = SimpleImputer()\n\n# Instantiate a knn model\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# Build steps for the pipeline\nsteps = [(\"imputer\", imputer), \n         (\"knn\", knn)]"},"cell_type":"code","id":"293a458d-fcbd-4914-bcd3-8632db2ce5b0","execution_count":12,"outputs":[]},{"source":"## Pipeline for song genre prediction: II\nHaving set up the steps of the pipeline in the previous exercise, you will now use it on the music_df dataset to classify the genre of songs. What makes pipelines so incredibly useful is the simple interface that they provide.","metadata":{},"cell_type":"markdown","id":"6b8ae2a7-cb1d-4f47-a498-e83b03631d62"},{"source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# Load data into a pandas DataFrame\ndf = pd.read_csv('datasets/music_clean.csv')\n\n# Check if 'target' is a valid column name\nif 'target' not in df.columns:\n    raise ValueError(\"Column 'target' not found in DataFrame\")\n\n# Split the data into training and testing sets\nX = df.drop('target', axis=1)\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define the imputer\nimp_mean = SimpleImputer(strategy='mean')\n\n# Define the classifier\nknn = KNeighborsClassifier()\n\nsteps = [(\"imputer\", imp_mean),\n        (\"knn\", knn)]\n\n# Create the pipeline\npipeline = Pipeline(steps)\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = pipeline.predict(X_test)\n\n# Print the confusion matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{},"cell_type":"code","id":"edf1745a-4eb8-41aa-9a03-48f0c05b8120","execution_count":null,"outputs":[]},{"source":"<script.py> output:\n    [[79  9]\n     [ 4 82]]","metadata":{},"cell_type":"code","id":"25e50f0e-d669-4939-9388-4daae82af4be","execution_count":null,"outputs":[]},{"source":"## Centering and scaling for regression","metadata":{},"cell_type":"markdown","id":"38f9a892-5183-46e2-90eb-d2f9d44cb7e0"},{"source":"# Import StandardScaler and Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\nX = df.drop(['target'], axis=1)\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create pipeline steps\nsteps = [(\"scaler\", StandardScaler()),\n         (\"lasso\", Lasso(alpha=0.5))]\n\n# Instantiate the pipeline\npipeline = Pipeline(steps)\npipeline.fit(X_train, y_train)\n\n# Calculate and print R-squared\nprint(pipeline.score(X_test, y_test))","metadata":{},"cell_type":"code","id":"99eee287-7b9f-40d4-8de5-d789f2d32bec","execution_count":null,"outputs":[]},{"source":"<script.py> output:\n    0.6193523316282489","metadata":{},"cell_type":"code","id":"79e8eb6f-fa34-4b7a-ad26-72b627e941f6","execution_count":null,"outputs":[]},{"source":"The model may have only produced an R-squared of 0.619, but without scaling this exact model would have only produced a score of 0.35, which proves just how powerful scaling can be","metadata":{},"cell_type":"markdown","id":"1ba1d8b8-44d5-4111-93ea-663b112fafd1"},{"source":"## Centering and scaling for classification","metadata":{},"cell_type":"markdown","id":"1cc7c4d1-df1e-49e0-bf2a-1c67f8549f8f"},{"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Build the steps\nsteps = [(\"scaler\", StandardScaler()),\n         (\"logreg\", LogisticRegression())]\npipeline = Pipeline(steps)\n\n# Create the parameter space\nparameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n                                                    random_state=21)\n\n# Instantiate the grid search object\ncv = GridSearchCV(pipeline, param_grid=parameters)\n\n# Fit to the training data\ncv.fit(X_train, y_train)\nprint(cv.best_score_, \"\\n\", cv.best_params_)","metadata":{"executionTime":23075,"lastSuccessfullyExecutedCode":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Build the steps\nsteps = [(\"scaler\", StandardScaler()),\n         (\"logreg\", LogisticRegression())]\npipeline = Pipeline(steps)\n\n# Create the parameter space\nparameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n                                                    random_state=21)\n\n# Instantiate the grid search object\ncv = GridSearchCV(pipeline, param_grid=parameters)\n\n# Fit to the training data\ncv.fit(X_train, y_train)\nprint(cv.best_score_, \"\\n\", cv.best_params_)"},"cell_type":"code","id":"5bf19a0d-66ab-4f78-a3cf-4e569987a203","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"0.05500000000000001 \n {'logreg__C': 0.6319473684210526}\n"}]},{"source":"Using a pipeline shows that a logistic regression model with \"C\" set to approximately 0.01 produces a model with 0.6319 accuracy!","metadata":{},"cell_type":"markdown","id":"a2da7412-4c51-496f-bc0d-6451808e3722"},{"source":"## Visualizing regression model performance\nNow we have seen how to evaluate multiple models out of the box, we will build three regression models to predict a song's \"energy\" levels.","metadata":{},"cell_type":"markdown","id":"afd77bfc-9973-497c-8e61-2962c76adb14"},{"source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import KFold, cross_val_score\nimport matplotlib.pyplot as plt\n\nmodels = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\nresults = []\n\n# Loop through the models' values\nfor model in models.values():\n  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n  \n  # Perform cross-validation\n  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n  \n  # Append the results\n  results.append(cv_scores)\n  \n# Create a box plot of the results\nplt.boxplot(results, labels=models.keys())\nplt.show()","metadata":{"executionTime":3062,"lastSuccessfullyExecutedCode":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import KFold, cross_val_score\nimport matplotlib.pyplot as plt\n\nmodels = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\nresults = []\n\n# Loop through the models' values\nfor model in models.values():\n  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n  \n  # Perform cross-validation\n  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n  \n  # Append the results\n  results.append(cv_scores)\n  \n# Create a box plot of the results\nplt.boxplot(results, labels=models.keys())\nplt.show()"},"cell_type":"code","id":"9af93e98-9cb0-4a15-83f5-14023c8edf2d","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"source":"Lasso regression is not a good model for this problem, while linear regression and ridge perform fairly equally. ","metadata":{},"cell_type":"markdown","id":"90491c6e-1387-403a-8a14-fc5b24c354b5"},{"source":"## Predicting on the test set","metadata":{},"cell_type":"markdown","id":"2460fa72-0ad3-400e-a2c2-1ccbad17844c"},{"source":"# Import mean_squared_error\nfrom sklearn.metrics import mean_squared_error\n\nfor name, model in models.items():\n  \n  # Fit the model to the training data\n  model.fit(X_train_scaled, y_train)\n  \n  # Make predictions on the test set\n  y_pred = model.predict(X_test_scaled)\n  \n  # Calculate the test_rmse\n  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))","metadata":{},"cell_type":"code","id":"3644c700-319e-45f2-8f3a-dd729a6b4860","execution_count":null,"outputs":[]},{"source":"<script.py> output:\n    Linear Regression Test Set RMSE: 0.11988851505947569\n    Ridge Test Set RMSE: 0.11987066103299668","metadata":{},"cell_type":"code","id":"96714e83-ff0e-4071-bbb7-2687a1c252e3","execution_count":null,"outputs":[]},{"source":"The linear regression model just edges the best performance, although the difference is a RMSE of 0.00001 for popularity! Now let's look at classification model selection.","metadata":{},"cell_type":"markdown","id":"15003165-a0fe-4649-8eba-f67dc4acc8b5"},{"source":"## Visualizing classification model performance","metadata":{},"cell_type":"markdown","id":"c06321ba-fff0-4339-a07e-b353a008ffc8"},{"source":"from sklearn.tree import DecisionTreeClassifier\n\n#Â Create models dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\nresults = []\n\n# Loop through the models' values\nfor model in models.values():\n  \n  #Â Instantiate a KFold object\n  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n  \n  # Perform cross-validation\n  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n  results.append(cv_results)\nplt.boxplot(results, labels=models.keys())\nplt.show()","metadata":{},"cell_type":"code","id":"90da518f-65c6-475c-91cf-815dd52e0cc3","execution_count":null,"outputs":[]},{"source":"![resim_2023-05-05_194130492](resim_2023-05-05_194130492.png)\n","metadata":{},"cell_type":"markdown","id":"3a197ae3-592c-4e78-8bc4-3ed7f4528092"},{"source":"Looks like logistic regression is the best candidate based on the cross-validation results! Let's wrap up by building a pipeline","metadata":{},"cell_type":"markdown","id":"c79a518e-4db3-44ee-ace6-f048f342c3ef"},{"source":"## Pipeline for predicting song popularity","metadata":{},"cell_type":"markdown","id":"1c5a53a2-8d32-4454-b029-f9f458facef2"},{"source":"# Create steps\nsteps = [(\"imp_mean\", SimpleImputer()), \n         (\"scaler\", StandardScaler()), \n         (\"logreg\", LogisticRegression())]\n\n# Set up pipeline\npipeline = Pipeline(steps)\nparams = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n\n# Create the GridSearchCV object\ntuning = GridSearchCV(pipeline, param_grid=params)\ntuning.fit(X_train, y_train)\ny_pred = tuning.predict(X_test)\n\n# Compute and print performance\nprint(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))","metadata":{},"cell_type":"code","id":"a2fc9d03-74bb-4d48-80d4-eff8179a27b5","execution_count":null,"outputs":[]},{"source":"<script.py> output:\n    Tuned Logistic Regression Parameters: {'logreg__C': 0.112, 'logreg__solver': 'newton-cg'}, Accuracy: 0.82","metadata":{},"cell_type":"code","id":"2281993e-3d1c-4951-b05e-a525632e324f","execution_count":null,"outputs":[]},{"source":"We've selected a model, built a preprocessing pipeline, and performed hyperparameter tuning to create a model that is 82% accurate in predicting song genres","metadata":{},"cell_type":"markdown","id":"e28332bc-bc1e-4c89-9b97-9c9a9c242978"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}